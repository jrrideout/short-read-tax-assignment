{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "usearch parameter sweep for taxonomic assignment\n",
      "================================================\n",
      "\n",
      "This notebook illustrates how to generate data that can be compared to the subject result data in the taxonomy assignment evaluation framework described in (Bokulich, Rideout, et al. (in preparation)). This is intended to illustrate how readers could test a concept for a new taxonomic assignment method, sweeping over a range of parameter settings, which could subsequently be evaluated with that evaluation framework. \n",
      "\n",
      "This code and other components of this framework can be found in the [short-read-tax-assignment GitHub repository](https://github.com/gregcaporaso/short-read-tax-assignment/).\n",
      "\n",
      "Overview\n",
      "--------\n",
      "\n",
      "To evaluate results generated with a custom taxonomy assigner (referred to here as the *query* results) against the pre-computed results from other taxonomic assigners (referred to here as the *subject* results), you only need to provide [BIOM](http://www.biom-format.org) files containing taxonomic assignments as observation metadata, where the observation metadata category is called ``taxonomy``. \n",
      "\n",
      "There are several steps in this process:\n",
      "\n",
      "1. Obtain test data from the [short-read-tax-assignment GitHub repository](https://github.com/gregcaporaso/short-read-tax-assignment/). This is achieved by cloning that repository to your local system. If you haven't used GitHub before, you can start [here](http://www.gitref.org) to learn about ``git`` and [here](https://help.github.com/categories/54/articles) to learn about GitHub. \n",
      "2. Apply your taxonomic assigner to the sequences included in the test data obtained in *Step 1*. These are formatted as standard multi-record fasta files.\n",
      "3. Add the resulting taxonomic assignments to the [BIOM](http://www.biom-format.org) files included in the test data obtained in *Step 1*. If you haven't used the BIOM format before, you should start [here](http://www.biom-format.org) to learn about BIOM. The most relevant funcitonality for this workflow is [adding metadata](http://biom-format.org/documentation/adding_metadata.html). The resulting BIOM tables should be called ``table.biom``.\n",
      "4. Store the BIOM tables resulting from *Step 3* in the required directory structure (covered in the next section).\n",
      "5. Run the evaluation framework, as illustrated in the evaluation framework IPython Notebook included in the [short-read-tax-assignment GitHub repository](https://github.com/gregcaporaso/short-read-tax-assignment/). You should only need to edit two directory paths to use that notebook to analyze your data.\n",
      "\n",
      "The code below illustrates how to test a concept for a usearch-based taxonomy assigner, which is similar in functionality to the uclust-based consensus taxonomy assinger in QIIME 1.7.0-dev and later. This code can take a while to run, so you may just want to use it as an example to see how you would generate data that can be analyzed with the evaluation framework. We note several lines of code that could be changed to reduce run time, if you do want to do a test run.\n",
      "\n",
      "Requirements\n",
      "------------\n",
      "\n",
      "If you are interested in running this code, rather that just using it as an example, you'll need the following software installed:\n",
      "\n",
      "* Python 2.7\n",
      "* [usearch](http://www.drive5.com/usearch/) v5.2.236. \n",
      "* [pyqi](http://bipy.github.io/pyqi/doc/index.html) 0.2.0\n",
      "* [biom-format](http://www.biom-format.org) 1.2.0\n",
      "* [uc_to_assignments](https://gist.github.com/gregcaporaso/6083538) (A gist written for use in this notebook)\n",
      "\n",
      "Structuring query results for comparison to subject results\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Your BIOM tables should be called ``table.biom``, and nested in the following directory structure:\n",
      "\n",
      "```\n",
      "query_results_dir/\n",
      " analysis/\n",
      "  dataset-id/ \n",
      "   reference-db-id/\n",
      "    method-id/\n",
      "     parameter-combination-id/\n",
      "      table.biom\n",
      "```\n",
      "\n",
      "``query_results_dir`` is the name of the top level directory, and you will set this value in the first code cell of this notebook. You can name this directory whatever you want to. The ``analysis`` directory should be called either ``mock`` or ``natural`` (indicating either mock or natural community analysis data). The ``dataset-id`` will be either the name of the specific mock community or natural community. The ``reference-db-id`` is the identifier for the reference database. The ``method-id`` is an identifier for your method. The ``parameter-combination-id`` is an identifier for your specific parameter combination. \n",
      "\n",
      "This directory structure is identical to that for the [subject results](https://github.com/gregcaporaso/short-read-tax-assignment/tree/master/data/eval-subject-results). You can review that directory structure for an example of how this should look and what directories are called in practice. These names are also pointed out in the comments of the code below. \n"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Prepare the environment."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from os.path import join, exists\n",
      "from os import makedirs\n",
      "from tempfile import mkstemp\n",
      "from glob import glob\n",
      "from pyqi.util import pyqi_system_call, remove_files"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Set paths to data files, code and output directory. If you are running this code on your own system, you'll need to update some paths in this section. This should be the only code that you *need* to update to run this."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "short_read_tax_dir = \"/Users/caporaso/Dropbox/code/short-read-tax-assignment/\"\n",
      "reference_seqs_fp = \"/Users/caporaso/data/gg_13_5_otus/rep_set/97_otus.fasta\"\n",
      "reference_tax_map = \"/Users/caporaso/data/gg_13_5_otus/taxonomy/97_otu_taxonomy.txt\"\n",
      "query_results_dir = \"/Users/caporaso/temp/usearch_parameter_sweep/\"\n",
      "uc_to_assignments_path = \"/Users/caporaso/code/uc_to_assignments/uc_to_assignments.py\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# create the output directory, ignore if it already exists.\n",
      "try:\n",
      "    makedirs(query_results_dir)\n",
      "except OSError:\n",
      "    pass\n",
      "mock_community_data_dir = join(short_read_tax_dir,\"data/qiime-mock-community\")\n",
      "natural_community_data_dir = join(short_read_tax_dir,\"data/natural-community\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Configure the parameter sweep. Here we define our method id, the reference database id, templates for the commands that we need to run, and the range of parameter settings that we want to sweep over. \n",
      "\n",
      "**IMPORTANT**: One reason that this notebook takes a while to run is that we sweep over a lot of different combinations of parameters. In the next cell we define 36 different parameter combinations, each of which gets run once per mock community. You can reduce the run time by reducing the range of parameter settings, for example to:\n",
      "\n",
      "```\n",
      "evalues = [0.001]\n",
      "queryfracts = [0.75]\n",
      "maxaccepts = [3]\n",
      "confidences = [0.51, 1.0]\n",
      "```"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "reference_db_id = \"gg_13_5_otus\"\n",
      "method_id = \"usearch\"\n",
      "\n",
      "# Define command templates\n",
      "usearch_cmd = \"usearch -query %s -db %s -uc %s -evalue %f -queryfract %f -maxaccepts %d\"\n",
      "uc_to_assignments_cmd = \" \".join([uc_to_assignments_path,\"-i %s -t %s -o %s -c %f\"])\n",
      "add_metadata_cmd = \"biom add-metadata -i %s -o %s --observation-metadata-fp %s --sc-separated taxonomy\"\n",
      "\n",
      "# Define the range of parameters that we want to sweep over. \n",
      "evalues = [1.0, 0.001]\n",
      "queryfracts = [0.50, 0.75]\n",
      "maxaccepts = [1, 3, 5]\n",
      "confidences = [0.51, 0.75, 1.0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Define a function to sweep over usearch parameters, applying them to each test data set. This function will be applied to analyze the mock and natural community test data."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def usearch_to_biom(input_data_dir,\n",
      "                    data_set_ids,\n",
      "                    results_dir,\n",
      "                    evalues,\n",
      "                    queryfracts,\n",
      "                    maxaccepts,\n",
      "                    confidences,\n",
      "                    usearch_cmd,\n",
      "                    uc_to_assignments_cmd,\n",
      "                    add_metadata_cmd,\n",
      "                    reference_db_id,\n",
      "                    method_id,\n",
      "                    reference_seqs_fp,\n",
      "                    reference_tax_map,\n",
      "                    input_table_filename_pattern='otu_table_mc2*biom'):\n",
      "                        \n",
      "    # Define a temporary filepath for the taxonomy map (i.e., the observation \n",
      "    # metadata file). This file can be big, but isn't used once the BIOM table \n",
      "    # gets created, so we'll create and overwrite this.\n",
      "    # Coding suggestion: It's a good idea to include prefix and suffix when \n",
      "    # creating temp files. It can help track the source of temp files\n",
      "    # accidentally being left around on your system.\n",
      "    result_tax_map_fp = mkstemp(suffix='.txt',prefix='usearch_tax')[1]\n",
      "    \n",
      "    # iterate over the mock community data sets\n",
      "    for data_set_id in data_set_ids:\n",
      "        # define the directory where the input data files \n",
      "        # can be found. these are the sequences to be classified (query_reads_fp)\n",
      "        # and the BIOM table without taxonomy metadata\n",
      "        data_set_input_dir = join(input_data_dir,data_set_id)\n",
      "        query_reads_fp = join(data_set_input_dir,'rep_set.fna')\n",
      "        biom_table_fp = glob(join(data_set_input_dir,\n",
      "                                  input_table_filename_pattern))[0]\n",
      "        \n",
      "        # define the path to the method-id directory. make that directory,\n",
      "        # doing nothing if it already exists.\n",
      "        method_id_output_dir = join(results_dir,\n",
      "                                    data_set_id,\n",
      "                                    reference_db_id,\n",
      "                                    method_id)\n",
      "        try:\n",
      "            makedirs(method_id_output_dir)\n",
      "        except OSError:\n",
      "            pass\n",
      "        \n",
      "        # iterate over the usearch parameter combinations to test.\n",
      "        for e in evalues:\n",
      "            for qf in queryfracts:\n",
      "                for ma in maxaccepts:\n",
      "                    # define an output uc file name. this is the raw output \n",
      "                    # from usearch, and this file will be processed to generate\n",
      "                    # taxonomy assignment results at different confidence levels.\n",
      "                    result_uc_fp = join(method_id_output_dir,\n",
      "                                        'e%f_qf%f_ma%d.uc' % (e, qf, ma))\n",
      "                    \n",
      "                    # this is for failure recovery - if a .uc file already exists,\n",
      "                    # just skip this iteration of the loop\n",
      "                    if exists(result_uc_fp):\n",
      "                        print \"%s exists, skipping.\" % result_uc_fp\n",
      "                        continue\n",
      "                    \n",
      "                    # define the usearch command that will be run for this iteration\n",
      "                    # of parameter settings.\n",
      "                    cmd = usearch_cmd % (query_reads_fp,\n",
      "                                         reference_seqs_fp,\n",
      "                                         result_uc_fp,\n",
      "                                         e,\n",
      "                                         qf,\n",
      "                                         ma)\n",
      "                    stdout, stderr, return_value = pyqi_system_call(cmd)\n",
      "                    assert return_value == 0,\\\n",
      "                     \"Invalid return value from command:\\n%s\\nstdout: %s\\nstderr: %s\" % (cmd,stdout,stderr)\n",
      "                    \n",
      "                    # iterate over the confidences. note that this is a parameter that comes in to play\n",
      "                    # after usearch completes, so we perform several iterations of analysis on a single \n",
      "                    # .uc file. each iteration here results in a taxonomy map file, which is formatted\n",
      "                    # as an observation metadata file. that metadata is then added to the current BIOM table.\n",
      "                    for c in confidences:\n",
      "                        \n",
      "                        parameter_combination_id = \"e%f_qf%f_ma%d_c%f\" % (e, qf, ma, c)\n",
      "                        parameter_combination_id_dir = join(method_id_output_dir,\n",
      "                                                            parameter_combination_id)\n",
      "                        makedirs(parameter_combination_id_dir)\n",
      "                        \n",
      "                        # define the command to generate taxonomic assignments from the .uc file \n",
      "                        # and run it. Note that result_tax_map_fp is a temp file which is overwritten\n",
      "                        # after each iteration (since the data gets added to the BIOM file).\n",
      "                        cmd = uc_to_assignments_cmd % (result_uc_fp,\n",
      "                                                       reference_tax_map,\n",
      "                                                       result_tax_map_fp,\n",
      "                                                       c)\n",
      "                        stdout, stderr, return_value = pyqi_system_call(cmd)\n",
      "                        assert return_value == 0,\\\n",
      "                         \"Invalid return value from command:\\n%s\\nstdout: %s\\nstderr: %s\" % (cmd,stdout,stderr)\n",
      "                        \n",
      "                        # define the name for the final BIOM file, and create that file by running\n",
      "                        # biom add-metadata.\n",
      "                        result_biom_table_fp = join(parameter_combination_id_dir,\n",
      "                                                    'table.biom')\n",
      "                        cmd = add_metadata_cmd % (biom_table_fp,\n",
      "                                                  result_biom_table_fp,\n",
      "                                                  result_tax_map_fp)\n",
      "                        stdout, stderr, return_value = pyqi_system_call(cmd)\n",
      "                        assert return_value == 0,\\\n",
      "                         \"Invalid return value from command:\\n%s\\nstdout: %s\\nstderr: %s\" % (cmd,stdout,stderr)\n",
      "                        \n",
      "                        # remove the temp file\n",
      "                        remove_files([result_tax_map_fp])\n",
      "                "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Apply usearch to the mock community test data, resulting in BIOM files nested in the correct directory structure."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This cell illustrates all steps to run ``usearch`` on the mock community test data, and generate BIOM files.\n",
      "\n",
      "**IMPORTANT**: Another reason why this notebook is slow is that it runs on a large number of mock community data sets. If you want to run this faster, you can reduce the number of data sets it's run on, for example to:\n",
      "\n",
      "```\n",
      "data_set_ids = [\n",
      " 'Broad-1',\n",
      " 'Turnbaugh-1']\n",
      "```"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "analysis = \"mock\"\n",
      "mock_query_results_dir = join(query_results_dir,analysis)\n",
      "data_set_ids = [\n",
      " 'Broad-1',\n",
      " 'Broad-2',\n",
      " 'Broad-3',\n",
      " 'S16S-1',\n",
      " 'S16S-2',\n",
      " 'Turnbaugh-1',\n",
      " 'Turnbaugh-2',\n",
      " 'Turnbaugh-3']\n",
      "\n",
      "usearch_to_biom(input_data_dir=mock_community_data_dir,\n",
      "                data_set_ids=data_set_ids,\n",
      "                results_dir=mock_query_results_dir,\n",
      "                evalues=evalues,\n",
      "                queryfracts=queryfracts,\n",
      "                maxaccepts=maxaccepts,\n",
      "                confidences=confidences,\n",
      "                usearch_cmd=usearch_cmd,\n",
      "                uc_to_assignments_cmd=uc_to_assignments_cmd,\n",
      "                add_metadata_cmd=add_metadata_cmd,\n",
      "                reference_db_id=reference_db_id,\n",
      "                method_id=method_id,\n",
      "                reference_seqs_fp=reference_seqs_fp,\n",
      "                reference_tax_map=reference_tax_map,\n",
      "                input_table_filename_pattern='otu_table_mc2*biom')\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Apply usearch to the natural community test data, resulting in BIOM files nested in the correct directory structure."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In this section we apply the same steps to the natural community data."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "analysis = \"natural\"\n",
      "natural_query_results_dir = join(query_results_dir,analysis)\n",
      "data_set_ids = [\n",
      " 'study_449']\n",
      "\n",
      "usearch_to_biom(input_data_dir=natural_community_data_dir,\n",
      "                data_set_ids=data_set_ids,\n",
      "                results_dir=natural_query_results_dir,\n",
      "                evalues=evalues,\n",
      "                queryfracts=queryfracts,\n",
      "                maxaccepts=maxaccepts,\n",
      "                confidences=confidences,\n",
      "                usearch_cmd=usearch_cmd,\n",
      "                uc_to_assignments_cmd=uc_to_assignments_cmd,\n",
      "                add_metadata_cmd=add_metadata_cmd,\n",
      "                reference_db_id=reference_db_id,\n",
      "                method_id=method_id,\n",
      "                reference_seqs_fp=reference_seqs_fp,\n",
      "                reference_tax_map=reference_tax_map,\n",
      "                input_table_filename_pattern='table.biom')\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}